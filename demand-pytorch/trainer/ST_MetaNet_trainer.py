import math 
import time
import numpy as np 
from data.utils import *
from data.datasets import ST_MetaNetDataset
from torch.utils.data import DataLoader
from trainer.base_trainer import BaseTrainer
from util.logging import * 
from logger.logger import Logger
from model import ST_MetaNet

class ST_MetaNetTrainer(BaseTrainer):
    def __init__(self, cls, config, args):
        self.config = config
        self.device = self.config.device
        self.cls = cls
        self.setup_save(args)
        self.logger = Logger(self.save_name)
    
    def load_dataset(self):
        with open(os.path.join(self.config.dataset_dir, self.config.dataset_name+".pickle"), "rb") as file:
            data = pickle.load(file)
        datasets = {}
        for category in ['train', 'val', 'test']:
            x, y = seq2instance(data[category].reshape(data[category].shape[0], -1), self.config.num_his, self.config.num_pred)
            if category == 'train':
                self.mean, self.std = np.mean(x), np.std(x)
            x = (x - self.mean) / self.std 
            datasets[category] = {'x': x, 'y': y}
        
        adj_feature = data['edge']
        src, dst = np.where(np.sum(adj_feature, axis=2) > 0)
        values = adj_feature[src, dst]
        adj_feature = (adj_feature - np.mean(values, axis=0)) / (np.std(values, axis=0) + 1e-8)
        graph = (adj_feature, src, dst)
        
        geo = data['node']
        feat = (geo - np.mean(geo, axis=0)) / (np.std(geo, axis=0) + 1e-8)
        Tensor = torch.cuda.FloatTensor
        feat = Tensor(feat)
        self.feat = feat
        return datasets, graph

    def setup_model(self):
        _, graph = self.load_dataset()
        self.model = ST_MetaNet.ST_MetaNetModel(graph= graph).to(self.device)

    def compose_dataset(self):
        datasets, _= self.load_dataset()
        for category in ['train', 'val', 'test']:
            datasets[category] = ST_MetaNetDataset(datasets[category])
        self.num_train_iteration_per_epoch = math.ceil(len(datasets['train']) / self.config.batch_size)
        self.num_val_iteration_per_epoch = math.ceil(len(datasets['val']) / self.config.test_batch_size)
        self.num_test_iteration_per_epoch = math.ceil(len(datasets['test']) / self.config.test_batch_size)
        return datasets['train'], datasets['val'], datasets['test']
    
    def compose_loader(self):
        train_dataset, val_dataset, test_dataset= self.compose_dataset()
        print(toGreen('Dataset loaded successfully ') + '| Train [{}] Test [{}] Val [{}]'.format(toGreen(len(train_dataset)), toGreen(len(test_dataset)), toGreen(len(val_dataset))))
        self.train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        self.val_loader = DataLoader(val_dataset, batch_size=self.config.test_batch_size, shuffle=False)
        self.test_loader = DataLoader(test_dataset, batch_size=self.config.test_batch_size, shuffle=False)

    def train_epoch(self, epoch):
        self.model.train()
        start_time = time.time()
        total_loss = 0
        total_metrics = np.zeros(len(self.metrics))
        
        for batch_idx, (data, target) in enumerate(self.train_loader):
            data, target = data.to(self.device).float(), target.to(self.device).float()
            self.optimizer.zero_grad()
            output = self.model(data, self.feat, target, 1)
            
            output = output * self.std 
            output = output + self.mean
            loss = self.loss(output, target) 
            loss.backward()
            self.optimizer.step()

            training_time = time.time() - start_time
            start_time = time.time()

            total_loss += loss.item()

            output = output.detach().cpu()
            target = target.detach().cpu()

            this_metrics = self._eval_metrics(output, target)
            total_metrics += this_metrics

            print_progress('TRAIN', epoch, self.config.total_epoch, batch_idx, self.num_train_iteration_per_epoch, training_time, self.config.loss, loss.item(), self.config.metrics, this_metrics)

        return total_loss, total_metrics

    def validate_epoch(self, epoch, is_test):
        self.model.eval()
        start_time = time.time()
        total_loss = 0
        total_metrics = np.zeros(len(self.metrics))
        

        for batch_idx, (data, target) in enumerate(self.test_loader if is_test else self.val_loader):
            data, target = data.to(self.device).float(), target.to(self.device).float()
            with torch.no_grad():
                output = self.model(data, self.feat, target, 0)
            output = output * self.std 
            output = output + self.mean

            loss = self.loss(output, target) 

            valid_time = time.time() - start_time
            start_time = time.time()

            total_loss += loss.item()

            output = output.detach().cpu()
            target = target.detach().cpu()

            this_metrics = self._eval_metrics(output, target)
            total_metrics += this_metrics

            print_progress('TEST' if is_test else 'VALID', epoch, self.config.total_epoch, batch_idx, \
                self.num_test_iteration_per_epoch if is_test else self.num_val_iteration_per_epoch, valid_time, \
                self.config.loss, loss.item(), self.config.metrics, this_metrics)
        
        return total_loss, total_metrics

